# -*- coding: utf-8 -*-
"""water potability prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-g70DriX9AmsYvq0SWI2xI4VgoCgbnUl
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data=pd.read_csv("/content/water_potability.csv")
data

data.columns

data.info()

data.isnull().sum()

data['ph']=data['ph'].fillna(data['ph'].mean())
data['Sulfate']=data['Sulfate'].fillna(data['Sulfate'].mean())
data['Trihalomethanes']=data['Trihalomethanes'].fillna(data['Trihalomethanes'].mean())

data

"""#1==potable(drinking water)
#0==not potable(not drinking water)

"""

data.isnull().sum()

data.corr()

import seaborn as sns
plt.figure(figsize=(16,8))
sns.heatmap(data.corr(),cmap="YlGnBu",annot=True)

data.corr()['Potability'].sort_values(ascending=False)

data=data.drop(data[['Turbidity','Trihalomethanes','ph','Conductivity']],axis=1)

data.columns

data

x=data.iloc[:,:-1]

x.columns

x

y=data.iloc[:,-1]

y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)

#knn
import sklearn
from sklearn.neighbors import KNeighborsClassifier

#finding and fitting best k value
for i in range(1,11):
   knn=KNeighborsClassifier(n_neighbors=i)
   knn.fit(x_train,y_train)
   print(i,knn.score(x_test,y_test))

#svm
from sklearn.svm import SVC
svc=SVC(kernel='linear')
svc.fit(x_train,y_train)
svc.score(x_test,y_test)

#svm
from sklearn.svm import SVC
svc=SVC(kernel='poly',degree=8)
svc.fit(x_train,y_train)
svc.score(x_test,y_test)

#svm
from sklearn.svm import SVC
svc=SVC(kernel='rbf')
svc.fit(x_train,y_train)
svc.score(x_test,y_test)

#svm
from sklearn.svm import SVC
svc=SVC(kernel='sigmoid')
svc.fit(x_train,y_train)
svc.score(x_test,y_test)

#logistic
from sklearn.linear_model import LogisticRegression
lg=LogisticRegression()
lg.fit(x_train,y_train)
lg.score(x_test,y_test)

#random forest
from sklearn.ensemble import RandomForestClassifier  
rf= RandomForestClassifier(n_estimators=200,criterion="entropy")  
rf.fit(x_train, y_train)  
rf.score(x_test,y_test)

#adaboost
from sklearn.ensemble import AdaBoostClassifier
abc=AdaBoostClassifier(n_estimators=100, random_state=0)
abc.fit(x_train, y_train)
rf.score(x_test,y_test)

from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)
clf.fit(x_train, y_train)
clf.score(x_test, y_test)

from sklearn.naive_bayes import GaussianNB  
nb = GaussianNB()  
nb.fit(x_train, y_train)
nb.score(x_test, y_test)

!pip install catboost
import catboost as cb
model_CBC = cb.CatBoostClassifier()
model_CBC.fit(x_train, y_train)
model_CBC.score(x_test, y_test)

"""#random forest have higher accuracy

"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
y_pred=rf.predict(x_test)
acc=accuracy_score(y_test,y_pred)
acc

cmatrix=confusion_matrix(y_test,y_pred)
sns.heatmap(cmatrix,annot=True,cmap="YlGnBu")

#saving model
import joblib
joblib.dump(rf,"water potability prediction.pkl")

load_model=joblib.load("water potability prediction.pkl")
load_model.score(x_test,y_test)

"""#--- c.jowin alfred"""